 

# v831AI训练部署教程

综述：该文章以在v831上部署AI模型为基础，主要将讲解AI的使用和训练方法，以及怎样部署到v831上。该教程主要分为三部分。第一部分讲述训练和模型转换的环境搭建，第二部分讲resnet18的模型训练部署，第三部分讲YOLOv2的模型训练部署。

## AI环境搭建

由于训练需要用到显卡，关于安装显卡驱动、cuda、udnn、opencv请自行百度查阅安装，本文不做详细说明。

可以参考：

* 显卡驱动：https://neucrack.com/p/252
* opencv多版本共存：https://neucrack.com/p/349

**训练环境安装：**

-  安装pytorch

打开[pytorch](https://pytorch.org/)官网，点击[Get Started](https://pytorch.org/get-started/locally/)进入到下载页面！选择对应pytorch进行下载！
我选择的是cpu版本！
安装torchsummary

  ~~~ bash
  pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html
  
  pip3 install torchsummary
  ~~~


- 编译onnx2ncnn工具

 工具github地址：https://github.com/Tencent/ncnn.git

~~~ bash
#!/bin/bash
sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev
git clone https://github.com/Tencent/ncnn.git
cd ncnn
git submodule update --init
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=OFF -DNCNN_BUILD_EXAMPLES=ON ..
make
~~~

编译完后你就得到了ncnn的一些工具。

在ncnn/build/tools/onnx目录下，能得到**onnx2ncnn**模型转换工具。你可以选择将该可执行文件加入到环境变量中方便使用，也可以选择不加，手动用该工具转换模型。



## 图像分类

### 数据集准备  

图像分类主要采用的模型是resnet18，由pytorch架构训练完成，经由网络模型转换后部署到v831上。

打开resnet18工程中的classifier_resnet_train.py文件。以下是训练时需要注意的一些描述量。

~~~ python
classes = ('car', 'chizi',"dog")		#分类的标签名字，注意要和数据集中的文件夹相对应
dataset_path = "data/datasets"		#训练集的路径
val_split_from_data = 0.1 # 10%		#学习率
batch_size = 4						#
learn_rate = 0.001	
total_epoch = 100					#训练循环，总共需要训练100个循环
eval_every_epoch = 5				#每个循环训练次数
save_every_epoch = 20				#多少个循环保存一次
dataload_num_workers = 2			#
input_shape = (3, 224, 224)			#输出尺寸
cards_id = [0]					#使用的训练卡
param_save_path = './out/classifier_{}.pth'	#参数保存路径
~~~

数据集：一个分类一个文件夹， 文件夹名字就是分类的名字

~~~ c
数据集文件夹结构
── car
│   ├── 20026.jpg
...
├── chizi
│   ├── 19418.jpg
...
└── dog
    ├── 19734.jpg
...
...
~~~

### 训练

> python classifier_resnet_train.py  

训练完成后，会在工程目录下生成一个out文件夹，在out文件夹下存放着训练过程中保存的训练参数。

~~~ bash
.
├── classifier_99.pth             #训练过程中保存的参数
├── classifier_final.pth          #训练完成后保存的参数
└── classifier.onnx               #生成的神经网络
~~~

### 测试  

准备好你的测试图片，注意和数据集中的图片尺寸一样。新建一个test目录，并放在该目录下。  
运行`python classifier_resnet_test.py images_folder_path model_param_path`命令进行测试。  
在该命令中会调用用户环境中的ncnn工具，请确保已经安装好并能运行。  
命令例子：  
~~~ bash 
python classifier_resnet_test.py ./test ./out/classifier_final.pth
~~~
```note: 训练和测试所用的设备需要相同。如果在gpu上训练，希望在gpu上部署，可以通过转换设备。代码更改参考下面。```
~~~ python
< net.load_state_dict(torch.load(param_save_path))      ##在gpu上训练
---
> net.load_state_dict(torch.load(param_save_path,map_location='cpu'))     ##在cpu上训练
~~~

运行完测试后，会生成ncnn模型和ncnn模型参数。  
生成的ncnn模型此时还无法被v831直接使用，需要经过在线maixhub量化为int8模型才可以被使用。有离线转换工具的用户可以使用离线工具转换。

### 模型转换  
有离线工具的用户可以跳过该步骤。参考离线工具使用手册.  

在线转换需要上传一个压缩包文件.  
- 该功能只能支持上传一个无密码的zip压缩包  
- 压缩包内需要包含一个 images 目录，一个 xxx.bin，一个 xxx.param  
- 需要将矫正图片放入 images 目录内；矫正图片集可考虑直接采用训练中的验证数据集，并务必保证矫正时图像的预处理方式与训练和部署时一致。   

zip压缩包目录结构
~~~ bash
└─xxxx.zip
    |─ images
    |    |- xxx.jpg
    |    |- ...
    |    ...
    |
    |- xxx.bin
    └─ xxx.param
~~~

制作好压缩包后打开网址:[https://maixhub.com/modelConvert](https://maixhub.com/modelConvert).  
![](https://neucrack.com/image/1/358/maixhub.jpg)  
登陆后,上传你的压缩包进行模型转换.    

等待模型转换完成,下载转换好的模型文件.  
得到的*.param和*.bin文件就是部署在v831上的文件.


LabelIMG 检测数据集制作 python 软件包  
安装：
```bash
pip install LabelIMG
```

使用:
```bash
labelImg
```