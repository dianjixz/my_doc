我用的是找轮廓的方法,根据轮廓层级,找到3层的轮廓,然后作为候选,就不去数点确认比例了.

### getContours
看我的步骤
~~~ python
    path = 'data/qrcode.jpg'
    img = cv2.imread(path)
    thresholdImage, contours, hierarchy = getContours(img)
~~~
首先把轮廓提取出来
~~~ python
def convert_img_to_binary(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    binary_img = cv2.adaptiveThreshold(
            gray,
            255,                    # Value to assign
            cv2.ADAPTIVE_THRESH_MEAN_C,# Mean threshold
            cv2.THRESH_BINARY,
            11,                     # Block size of small area
            2,                      # Const to substract
        )
    return binary_img

def getContours(img):
    binary_img = convert_img_to_binary(img)
    thresholdImage = cv2.Canny(binary_img, 100, 200) #Edges by canny edge detection
    _, contours, hierarchy = cv2.findContours(
            thresholdImage, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    return thresholdImage, contours, hierarchy
~~~
把图片预处理了一下,首先二值化,然后做一下canny提取边缘信息,就成了这样
![canny](https://blog.357573.com/2020/07/03/opencv实现二维码检测/canny.jpg)  
,然后调opencv的<code>findContours</code>函数,找到轮廓,
![轮廓](https://blog.357573.com/2020/07/03/opencv实现二维码检测/contours.jpg)  
结果发现全是轮廓,哈哈,不急,我们慢慢挑,最重要的是最后那个返回值,也就是层级关系.这个是我们算法的核心信息.

然后我们就要开始利用这个层级关系了,因为二维码轮廓是黑白黑三层的,所以我们搜索所有三层的轮廓
~~~ python
    # qrcode corner has 3 levels
    levelsNum = 3
    patterns, patternsIndices = getContourWithinLevel(levelsNum, contours, hierarchy)
~~~
看一下这个怎么搜索的
### getContourWithinLevel
~~~ python
def isPossibleCorner(contourIndex, levelsNum, contours, hierarchy):
    # if no chirld, return -1
    chirldIdx = hierarchy[0][contourIndex][2] 
    level = 0
    while chirldIdx != -1:
        level += 1
        chirldIdx = hierarchy[0][chirldIdx][2] 
    if level >= levelsNum:
        return checkRatioOfContours(contourIndex, contours, hierarchy)
    return False

def getContourWithinLevel(levelsNum, contours, hierarchy):
    # find contours has 3 levels
    patterns = []
    patternsIndices = []
    for contourIndex in range(len(contours)):
        if isPossibleCorner(contourIndex, levelsNum, contours, hierarchy):
            patterns.append(contours[contourIndex])
            patternsIndices.append(contourIndex)
    return patterns, patternsIndices
~~~
也就是找到有3层子轮廓的轮廓,把它返回回来,其中<code>hierarchy</code>这个对象,固定的shape是<code>1,n,4</code>其中n是轮廓的数量,例如我们这个例子就是<code>(1, 1253, 4)</code>,最后那个4个维度代表<code>下一个轮廓id,上一个轮廓id,子轮廓id,父轮廓id</code>如果没有的话统统都是-1,所以我们这里获得<code>hierarchy[0][contourIndex][2]</code>就是获取了子轮廓的id,然后就数连着3级都有子轮廓就存下来,但是也不是都存下来了,因为最后还有一个<code>checkRatioOfContours</code>函数,这个是防止子轮廓大小比例异常
~~~ python
def checkRatioOfContours(index, contours, hierarchy):
    firstChildIndex = hierarchy[0][index][2]
    secondChildIndex = hierarchy[0][firstChildIndex][2]
    firstArea = cv2.contourArea(contours[index]) / (
        cv2.contourArea(contours[firstChildIndex]) + 1e-5)
    secondArea = cv2.contourArea(contours[firstChildIndex]) / (
        cv2.contourArea(contours[secondChildIndex]) + 1e-5)
    return ((firstArea / (secondArea+ 1e-5)) > 1 and \
            ((firstArea / (secondArea+ 1e-5)) < 10))
~~~
所以我比较了一下,父轮廓的大小要在子轮廓的1-10倍之间,不然就算噪声排除掉了.
现在看看还剩下多少轮廓
![轮廓](https://blog.357573.com/2020/07/03/opencv实现二维码检测/contours2.jpg)  
这样一挑,就只剩下8个轮廓了.
如果图片特别模糊,看不清是3个层级怎么办,我们后续也加了一步
~~~ python
    #in case not all the picture has clear pattern
    while len(patterns) < 3 and levelsNum > 0:
        levelsNum -= 1
        patterns, patternsIndices = getContourWithinLevel(levelsNum, contours, hierarchy)
~~~
如果找到的关键点还不够3个,那么我们就减小层级,这样假设太小了的,三层只能看见两层的我们也能找到,所以我们逐步缩小了层级,直到找够3个为止
找到之后就开始处理了,如果此时还不3个就直接宣告GG吧,也不浪费时间了
~~~ python
    interstingPatternList = []
    if len(patterns) < 3 :
        print('no enough pattern')
        return False, []
        # return False
~~~
如果刚好找到了3个,那就把这3个都作为感兴趣的轮廓加进去
~~~ python
    elif len(patterns) == 3:
        for patternIndex in range(len(patterns)):
            x, y, w, h = cv2.boundingRect(patterns[patternIndex])
            interstingPatternList.append(patterns[patternIndex])

        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
        show(img, 'qrcode')
        # return patterns
~~~
如果比3个多,我们就要把父轮廓提取出来,刚才那8个都是一个父轮廓带着一个子轮廓的,现在我们要把这个父轮廓提取出来,子轮廓就不要了.
我们来挨个判断一下,把那些没有爸爸的加到感兴趣的里面,但是这样有个问题,如果有的有爸爸,但是他的爸爸在早期就被淘汰了,例如有的图整张图片有个超大的圈,所有图案都是外面那个圈的子轮廓,这时候我们就不能从全局去找爸爸了,那该怎么办呢?我们就从这8个待选的轮廓中找爸爸.
~~~ python
    elif len(patterns) > 3:
        # sort from small to large
        patternAreaList = np.array(
                [cv2.contourArea(pattern) for pattern in patterns])
        areaIdList = np.argsort(patternAreaList)
        # get patterns without parents
        intrestingPatternIdList = []
        for i in range(len(areaIdList) - 1, 0, -1):
            index = patternsIndices[areaIdList[i]]
            if hierarchy[0][index][3] == -1:
                intrestingPatternIdList.append(index)
            else:
                # We can make sure the parent must appear before chirld because we sorted the list by area
                if not isParentInList(intrestingPatternIdList, index, hierarchy):
                    intrestingPatternIdList.append(index)

        for intrestingPatternId in intrestingPatternIdList:
            x, y, w, h = cv2.boundingRect(contours[intrestingPatternId])
            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
            interstingPatternList.append(contours[intrestingPatternId])
        show(img, 'qrcode')
~~~
我们先给这些轮廓按照大小排个序,这样的话从大到小来判断,就可以优先提取出最大的了,剩下的绝对不可能是前一个的父轮廓,所以我们每个轮廓就判断一下它有没有爸爸已经被我们选中了即可.
这下我们搜集的所有轮廓都不互为父子了.
![轮廓](https://blog.357573.com/2020/07/03/opencv实现二维码检测/contours3.jpg) 
我们再看现在剩下的轮廓,有一个在小电视上,那是我们不希望存在的,现在就要想办法把它除掉.
首先使用距离肯定是不合适的,因为小电视明显和最下面的那个最近,用全部距离的话会把右上角那个点去掉,把小电视保留.
那么我们就用角度好了,每三个点都找一遍,选出两条垂直并且长度也差不多的线
现在是轮廓,我们要把它变成点
首先每个轮廓找到他自己的重心
~~~ python
    centerOfMassList = getCenterOfMass(interstingPatternList)
    for centerOfMass in centerOfMassList:
        cv2.circle(img_show, tuple(centerOfMass), 3, (0, 255, 0))
~~~
结果如下
![重心](https://blog.357573.com/2020/07/03/opencv实现二维码检测/mass.jpg)
找重心的函数是
~~~ python
def getCenterOfMass(contours):
    pointList = []
    for i in range(len(contours)):
        moment = cv2.moments(contours[i])
        centreOfMassX = int(moment['m10'] / moment['m00'])
        centreOfMassY = int(moment['m01'] / moment['m00'])
        pointList.append([centreOfMassX, centreOfMassY])
    return pointList
~~~

我是通过计算图像的矩来找的重心,说白了也就是哪边点多就往哪边偏移,这符合重心的原理.当然直接用轮廓找个重心也是可以的,但是这样噪声影响比较大.
找到重心之后我们要挑出最终的三个点
~~~ python
    id1, id2, id3 = 0, 1, 2
    if len(patterns) > 3:
        result = selectPatterns(centerOfMassList)
        if result is None:
            print('no correct pattern')
            return False, []
        id1, id2, id3 = result
~~~
### selectPatterns
~~~ python
def selectPatterns(pointList):
    lineList = []
    for i in range(len(pointList)):
        for j in range(i, len(pointList)):
            lineList.append([i, j])
    finalLineList = []
    finalResult = None
    minLengthDiff = -1
    for i in range(len(lineList)):
        for j in range(i, len(lineList)):
            line1 = np.array([pointList[lineList[i][0]][0] -  pointList[lineList[i][1]][0], 
                pointList[lineList[i][0]][1] -  pointList[lineList[i][1]][1]])
            line2 = np.array([pointList[lineList[j][0]][0] -  pointList[lineList[j][1]][0], 
                pointList[lineList[j][0]][1] -  pointList[lineList[j][1]][1]])
            pointIdxList = np.array([lineList[i][0], lineList[i][1], lineList[j][0], lineList[j][1]])
            pointIdxList = np.unique(pointIdxList)
            # print('****')
            if len(pointIdxList) == 3:
                theta = lineAngle(line1, line2)
                if abs(math.pi / 2 - theta) < math.pi / 6:
                    lengthDiff = abs(np.linalg.norm(line1, axis = 0) - np.linalg.norm(line2, axis = 0))
                    if  lengthDiff < minLengthDiff or minLengthDiff < 0:
                        minLengthDiff = abs(np.linalg.norm(line1, axis = 0) - np.linalg.norm(line2, axis = 0))
                        finalResult = pointIdxList

    
    return finalResult
~~~
我的做法是每3个点做两条线段,然后判断线段如果差不多90度,我这里的范围比较宽松,可以浮动30度,也就是说你夹角只要在60-120度之间的都可以进入下一步,下一步就是从所有夹角符合的情况中选出线段长度最接近的,也就是<code>minLengthDiff</code>这一组,恭喜这三个点两条线获胜,就是我们想要的轮廓.

最后就是来计算旋转角度了,也就是看这三个点哪个是左下,哪个是左上,哪个是右上
~~~ python
    interstingPatternList = np.array(interstingPatternList)[[id1, id2, id3]]
    centerOfMassList = np.array(centerOfMassList)[[id1, id2, id3]]
    pointList = getOrientation(interstingPatternList, centerOfMassList)
~~~
### getOrientation
~~~ python
def getOrientation(contours, centerOfMassList):
        distance_AB = np.linalg.norm(centerOfMassList[0].flatten() - centerOfMassList[1].flatten(), axis = 0)
        distance_BC = np.linalg.norm(centerOfMassList[1].flatten() - centerOfMassList[2].flatten(), axis = 0)
        distance_AC = np.linalg.norm(centerOfMassList[0].flatten() - centerOfMassList[2].flatten(), axis = 0)

        largestLine = np.argmax(
            np.array([distance_AB, distance_BC, distance_AC]))
        bottomLeftIdx = 0
        topLeftIdx = 1
        topRightIdx = 2
        if largestLine == 0:
            bottomLeftIdx, topLeftIdx, topRightIdx = 0, 2, 1 
        if largestLine == 1:
            bottomLeftIdx, topLeftIdx, topRightIdx = 1, 0, 2 
        if largestLine == 2:
            bottomLeftIdx, topLeftIdx, topRightIdx = 0, 1, 2 

        # distance between point to line:
        # abs(Ax0 + By0 + C)/sqrt(A^2+B^2)
        slope = (centerOfMassList[bottomLeftIdx][1] - centerOfMassList[topRightIdx][1]) / (centerOfMassList[bottomLeftIdx][0] - centerOfMassList[topRightIdx][0] + 1e-5)
        # y = kx + b => AX + BY +C = 0 => B = 1, A = -k, C = -b
        coefficientA = -slope
        coefficientB = 1
        constant = slope * centerOfMassList[bottomLeftIdx][0] - centerOfMassList[bottomLeftIdx][1]
        distance = (coefficientA * centerOfMassList[topLeftIdx][0] + coefficientB * centerOfMassList[topLeftIdx][1] + constant) / (
            np.sqrt(coefficientA ** 2 + coefficientB ** 2))


        pointList = np.zeros(shape=(3,2))
        # 回    回   tl   bl
        if (slope >= 0) and (distance >= 0):
            # if slope and distance are positive A is bottom while B is right
            if (centerOfMassList[bottomLeftIdx][0] > centerOfMassList[topRightIdx][0]):
                pointList[1] = centerOfMassList[bottomLeftIdx]
                pointList[2] = centerOfMassList[topRightIdx]
            else:
                pointList[1] = centerOfMassList[topRightIdx]
                pointList[2] = centerOfMassList[bottomLeftIdx]
            # TopContour in the SouthWest of the picture
            ORIENTATION = "SouthWest"

        # 回   回     bl     tl
        #
        #      回            tr
        elif (slope > 0) and (distance < 0):
            # if slope is positive and distance is negative then B is bottom
            # while A is right
            if (centerOfMassList[bottomLeftIdx][1] > centerOfMassList[topRightIdx][1]):
                pointList[2] = centerOfMassList[bottomLeftIdx]
                pointList[1] = centerOfMassList[topRightIdx]
            else:
                pointList[2] = centerOfMassList[topRightIdx]
                pointList[1] = centerOfMassList[bottomLeftIdx]
            ORIENTATION = "NorthEast"


        #       回            bl
        #
        # 回    回      tr    tl
        elif (slope < 0) and (distance > 0):
            if (centerOfMassList[bottomLeftIdx][0] > centerOfMassList[topRightIdx][0]):
                pointList[1] = centerOfMassList[bottomLeftIdx]
                pointList[2] = centerOfMassList[topRightIdx]
            else:
                pointList[1] = centerOfMassList[topRightIdx]
                pointList[2] = centerOfMassList[bottomLeftIdx]
            ORIENTATION = "SouthEast"
        # 回    回    tl   tr
        #
        # 回          bl
        elif (slope < 0) and (distance < 0):

            if (centerOfMassList[bottomLeftIdx][0] > centerOfMassList[topRightIdx][0]):
                pointList[2] = centerOfMassList[bottomLeftIdx]
                pointList[1] = centerOfMassList[topRightIdx]
            else:
                pointList[2] = centerOfMassList[topRightIdx]
                pointList[1] = centerOfMassList[bottomLeftIdx]
        pointList[0] = centerOfMassList[topLeftIdx]
        return pointList
~~~
我这里其实就是先用距离找出离两个距离最远的点,剩下一个就是直角点了,然后算出斜边的斜率,再算出直角点在斜边的哪一侧,就可以得出这个图形的旋转方式.
最终就可以得到我们想要的三个点了,我返回时候是按照左上角,左下角,右上角的这个顺序返回的.
看看识别结果
![结果](https://blog.357573.com/2020/07/03/opencv实现二维码检测/result.jpg)
![结果](https://blog.357573.com/2020/07/03/opencv实现二维码检测/result2.jpg)
