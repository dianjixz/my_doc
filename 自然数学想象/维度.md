关于维度空间的公理:
维度是分离的。（不同维度之间没有任何的联系，即维度之间不能进行干预。）
维度之间可进行投影。（不同维度之间的参量可以进行投影转换。）
维度不可被跨越。（不同维度之间不存在相互跨越的关系。）

维度推论演化：
单位：在数学上不可再分割的一个大小标量。
单位基量，在唯一维度方向上的一个单位矢量。又称维度向量。
维度基量 ：在维度空间内，由维度数个正交单位基量组成的基量组，为维度基量。维度基量是维度空间中的基本单位，维度空间内只存在维度空间内的维度基量。其属性的最小值是单位个。又称维度向量基。
向量的位置，总是从零点出发到结束点。


维度集合描述：
    有限个维度量构成的集合，为维度集合，简称维度集。

维度集的整体分布视为形状。
而形状具有边缘。


信息在维度中的描述：
    信息是维度空间内维度集合的表述。

维度共振描述：
    当两个维度集合相同时，输出的共振量就会越大。当维度集合完全相同时，共振会达到无穷大。
    维度共振可以使用余弦距离，将维度集于维度集进行余弦运算，能得出两个维度集之间的维度最小角度，有了角度便有了共振。

如何应用维度共振选出我们期望的维度数据呢？
如何选定维度共振边界。

维度集合和维度量的关系。
维度集合和维度集合的关系。
分离，包含，重合。三大关系在维度集中如何进行判断。


维度集合的属性，
形状，大小。

缩放系数。不同层面相关的数据也会变。
形状描述，集合的缩放系数。匹配形状的向量基。



集合判断时会有一个自然数 E 。
2.718281828459045

判断时会有一个中间态，是，不是，分界点在 E，上。

无视形状可以进行拓扑，形态拓展。


三角函数和复数的转换可以将原来的数据跨越到新的维度上。


完美呀，将三角函数推广到多维，完美。



 0 - 1 - 2 - 3 - 无穷。


人的大脑也是需要随机数据进行碰撞的。



信息论中的一些摘要：

# 信息论基础 学习笔记（1）https://zhuanlan.zhihu.com/p/84828413

信息熵



接下来，我们定义 **信息熵（Information Entropy）**，事实上信息熵的表达形式的证明是严格的。信息熵是指，先验的，X的值有P(X=x_i)的概率为x_i，因此，确定X究竟是哪个值所需要的信息就是就是各个取值的自信息的期望，即：

![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+H_p%28X%29%26%3D%5Cmathbb%7BE%7D%5C+I_p%28X%3Dx_i%29%5C%5C+%26%3D%5Cmathbb%7BE%7D%5Clog+%5Cfrac%7B1%7D%7Bp%28X%3Dx_i%29%7D%5C%5C+%26%3D%5Csum+p%28X%3Dx_i%29%5Clog+%5Cfrac%7B1%7D%7Bp%28X%3Dx_i%29%7D+%5Cend%7Baligned%7D+)

同理，我们可以构造多变量的**联合熵**和**条件熵**:

![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+H_p%28X%2CY%29%3D%5Csum+p%28X%3Dx_i%2CY%3Dy_j%29%5Clog+%5Cfrac%7B1%7D%7Bp%28X%3Dx_i%2CY%3Dy_j%29%7D%5C%5C+H_p%28X%7CY%29%3D%5Csum+p%28X%3Dx_i%2CY%3Dy_j%29%5Clog+%5Cfrac%7B1%7D%7Bp%28X%3Dx_i%7CY%3Dy_j%29%7D+%5Cend%7Baligned%7D)

显然，信息熵是随机变量的函数，下标表达该随机变量遵循的是p分布,多变量的时候表达联合分布或条件分布，这个下标常常省略。事实上，上述三种表达方式都很常用，尤其是在信息论的相关证明中。为什么信息熵的表达式是这样的？因为它要满足一些条件，这些条件往往是由直觉给出的。给出条件的人其中包括了香浓Shannon和维纳·辛钦A.I.Khinchin。这里列出辛钦给出的条件：

1. 连续性。把p看作是参数，那么 ![[公式]](https://www.zhihu.com/equation?tex=H_p%28X%29) 随p的变化是连续的。
2. 独立相加性。 ![[公式]](https://www.zhihu.com/equation?tex=H%28X%2CY%29%3DH%28X%29%2BH%28Y%29) ，如果X与Y独立。
3. 可加性。即部分与整体的关系。令 ![[公式]](https://www.zhihu.com/equation?tex=H%28X%29%3Df%28p%28x_1%29%2Cp%28x_2%29%2C%5Cdots%2Cp%28x_k%29%29) . 如果把前m个取值看作一体，一个 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctilde%7Bp%7D%3Dp%28x_1%29%2Bp%28x_2%29%2B%5Cdots+%2Bp%28x_m%29) ，那么 ![[公式]](https://www.zhihu.com/equation?tex=f%28p%28x_1%29%2Cp%28x_2%29%2C%5Cdots%2Cp%28x_k%29%29%3Df%28%5Ctilde%7Bp%7D%2Cp%28x_%7Bk%2B1%7D%29%2C%5Cdots%2Cp%28x_k%29%29%2B%5Ctilde%7Bp%7Df%28p%27%28x_1%29%2C%5Cdots%2Cp%27%28x_m%29%29) 
   其中， ![[公式]](https://www.zhihu.com/equation?tex=p%27%28x_i%29%3Dp%28x_i%29%2F%5Ctilde%7Bp%7D%E2%80%8B) ，即重新归一化后的概率
4. 极值条件。 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmax+H_p%28X%29%3DH_u%28X%29) . 其中 u 表示均匀分布。这里指，在随机变量的取值均匀分布的时候，信息熵最大
5. 零概率事件不影响信息熵。即，如果X的k个取值中多出一个 ![[公式]](https://www.zhihu.com/equation?tex=X_%7Bk%2B1%7D) ，它的概率为0，那么， ![[公式]](https://www.zhihu.com/equation?tex=H_%7Bp%27%7D%3DH_p).也可以写成：     ![[公式]](https://www.zhihu.com/equation?tex=f%28p%28x_1%29%2Cp%28x_2%29%2C%5Cdots%2Cp%28x_k%29%2C0%29%3Df%28p%28x_1%29%2Cp%28x_2%29%2C%5Cdots%2Cp%28x_k%29%29) 

通过以上的条件就可以严格得到信息熵的数学表达式。 







在做信息选取的时候，我们首先要进行信息的判断。判断获取的信息中有没有价值，如果没有价值就不进行选取了。
信息价值的判断就靠信息熵来判断。越是混乱的信息，信息熵越大。

经过编码的信息，信息熵比较低。

任何低熵信息都具有维度基，维度基可以进行傅立叶计算。

具有周期性，重复性的信息，这样的信息视为低熵有价值的信息。
周期性，重复性可以用傅立叶变换进行变换。
周期性、重复性、可递推性。

在时空维度中，
延时，叠加，倍率。
齐次性。




所谓的「齐」，必然是有两个或者以上的对象，那么就以两个对象为例齐次，是指所列的式子只和相关，不存在的项，包括常数项也只有0所以方程可以写成的形式，函数可以写成的形式当同时变成倍时，即，方程仍然成立，而函数，也就是在特定的变换下保持某种不变性或者规律性，物理上叫做对称性，拥有某种对称性将给我们的工作带来极大的方便









脑神经的重启制度，当无用碰撞过多时，脑神经会关闭这种无用的碰撞。睡觉等人们休眠手段重新刷新了神经元的碰撞阈值，这样人们就开始有精力重新去学习，工作，劳动。































